{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6cb4678",
   "metadata": {},
   "source": [
    "# Practicals for lecture 1.2\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/vigji/python-cimec/blob/main/practicals/Practicals_1.2.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f912d13",
   "metadata": {},
   "source": [
    "#### 1.0.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef491f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "\n",
    "\n",
    "def generate_RT_data(n_subjects=200, n_samples_per_subject=1000):\n",
    "    \"\"\"\n",
    "    Generates Reaction Time data for a given number of subjects, each with their own distribution parameters.\n",
    "    \n",
    "    Parameters:\n",
    "    n_subjects (int): Number of subjects\n",
    "    n_samples_per_subject (int): Number of samples (RT times) per subject\n",
    "    \n",
    "    Returns:\n",
    "    np.ndarray: A 2D array where each row represents the RT times for a subject\n",
    "    \"\"\"\n",
    "    np.random.seed(0)  # For reproducibility\n",
    "    shift = 0.500  # Shift of the distribution\n",
    "    # Initialize an empty array to store the RT times for all subjects\n",
    "    RT_data = np.empty((n_subjects, n_samples_per_subject))\n",
    "    \n",
    "    for i in range(n_subjects):\n",
    "        # Assuming mu ranges from 90 to 110 and sigma from 10 to 20 for the subjects\n",
    "        mu = np.random.uniform(0.090, 0.110)\n",
    "        sigma = np.random.uniform(0.10, 0.20)\n",
    "        RT_data[i] = np.random.normal(mu, sigma, n_samples_per_subject) + shift\n",
    "    \n",
    "    return RT_data\n",
    "\n",
    "\n",
    "def download_meteo_data(start_date=\"2022-01-01\", end_date=\"2022-12-31\",\n",
    "                        latitude=\"45.88204\", longitude=\"11.03647\",\n",
    "                        data=\"temperature_2m\"):\n",
    "    \"\"\"Download meteo historical data from open-meteo.com.\n",
    "    \"\"\"\n",
    "    BASE_URL = \"https://archive-api.open-meteo.com/v1/\"\n",
    "    query = f\"archive?latitude={latitude}&longitude={longitude}&start_date={start_date}&end_date={end_date}&hourly={data}\"\n",
    "\n",
    "    r = requests.get(BASE_URL + query)\n",
    "    json_dict = json.loads(r.text)\n",
    "    \n",
    "    if \"hourly\" not in json_dict.keys():\n",
    "        print(json_dict)\n",
    "        return None, None\n",
    "    else:\n",
    "        return (np.array(json_dict[\"hourly\"][k]) for k in [\"time\", data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55078aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the index of the subject with the shortest trial reaction time of the whole dataset \n",
    "# (not shortest average!)\n",
    "# (Hint: you will need two operations...)\n",
    "rt_data = generate_RT_data(n_subjects=10)\n",
    "rt_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8dbe38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use argmax to find the index of the warmest hour in the (non-reshaped) temperature_array.\n",
    "# Then, use the index over timestamps_array to read out the corresponding timestamp.\n",
    "timestamps_array, temperatures_array = download_meteo_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50091306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use the np.argsort() function to produce the indexes array required to\n",
    "# order an array in ascending or descending values.\n",
    "\n",
    "# Let's make a ranking of the 5 warmest hours of 2022! \n",
    "# Sort the (non-reshaped) temperature array using the indexes produced by np.argsort.\n",
    "# so that the first elements are the highest temperatures.\n",
    "# Then sort the imestamps array with the same indexes, and take the first 5.\n",
    "#\n",
    "# Double check you match the result that you have got in the exercises above!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f82fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a boolean selector to filter all temperatures above 10 and below 25:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c4101ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2022-01-01T00:00', '2022-01-01T01:00', '2022-01-01T02:00', ...,\n",
       "       '2022-12-31T21:00', '2022-12-31T22:00', '2022-12-31T23:00'],\n",
       "      dtype='<U16')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (Bonus):\n",
    "# Let's do the same, but only for the months between january and March, and only for hours between 08 and 18.\n",
    "\n",
    "# To get the condition on month and hours, you will have to parse the timestamp string, or explore\n",
    "# the timedate library for more elegant solutions!\n",
    "\n",
    "timestamps_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2a4f38",
   "metadata": {},
   "source": [
    "## Introduction to `pandas`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472faa0d",
   "metadata": {},
   "source": [
    "#### 1.2.0 Numpy bool; Create and index dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371d3fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecba7d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy bool operations\n",
    "# Take the array of integer numbers below. Use array boolean operations to filter out the numbers that \n",
    "# are greater than 5 AND less than 8, OR that are multiple of 7.\n",
    "np.random.seed(42)\n",
    "an_array = np.random.randint(0, 10, 100)\n",
    "\n",
    "an_array[((an_array > 5) & (an_array < 8)) | (an_array % 7 == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d753478",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_data = ['cabbage', 'artichoke', 'banana', 'avocado', 'apple', 'orange']\n",
    "int_data = [1, 2, 3, 4, 5, 6]\n",
    "float_data = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "\n",
    "# Put together the data above in a DataFrame. What happens if you don't specify the index?\n",
    "\n",
    "df = pd.DataFrame(dict(string_data=string_data, int_data=int_data, float_data=float_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5446f27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the column of the dataframe containing the strings using the name of the column\n",
    "\n",
    "df[\"string_data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db398d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the first two rows of the dataframe\n",
    "df.loc[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acf9ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640df587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the rows of the dataframe so that the float data is greater than 0.2\n",
    "\n",
    "df.loc[df[\"float_data\"] > 0.2, \"string_data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269635a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the rows of the dataframe so that the float data is greater than 0.2 and the int data is less than 5\n",
    "df.loc[(df[\"float_data\"] > 0.2) & (df[\"int_data\"] < 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73b2dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the .loc property to select the value of the float data in the row with index 3\n",
    "df.loc[3, \"float_data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984af9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column to the dataframe containing the following data entries:\n",
    "new_data = [500, 300, 200, 400, 600, 500]\n",
    "\n",
    "df[\"new_col\"] = new_data\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457f31e7",
   "metadata": {},
   "source": [
    "#### 1.2.1 Methods of `pandas` dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20a15d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we create a fake dataframe containing the results of an psychological test with 30 subjects.\n",
    "# Subjects can be left-handed or right-handed.\n",
    "# The test has 2 measures (reaction time - RT, and accuracy)\n",
    "def create_data_df():\n",
    "    np.random.seed(42)\n",
    "    subject_ability = np.random.uniform(0, 1, 30)\n",
    "    return pd.DataFrame({'subject': [f\"subject_{i}\" for i in range(30)],\n",
    "                       'handedness': np.random.choice(['left', 'right'], 30),\n",
    "                       'RT': subject_ability*100 + np.random.uniform(0, 50, 30),\n",
    "                       'accuracy': subject_ability + np.random.normal(0.8, 0.1, 30)})\n",
    "df = create_data_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581126bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the dataframe by RT:\n",
    "df.sort_values(by=\"RT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f400f63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean and standard deviation of the RT and accuracy across the dataset:\n",
    "df[[\"RT\", \"accuracy\"]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba8c60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use indexing to select the RT of the left-handed subjects, and compute its 90% percentile:\n",
    "lefthand_rt_90perc = df.loc[df[\"handedness\"] == \"left\", \"RT\"].quantile(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5544450f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now use the percentile to select the accuracy for left-handed subjects with RT above the 90% percentile:\n",
    "lefthanded_df = df[df[\"handedness\"] == \"left\"]\n",
    "lefthanded_df.loc[lefthanded_df[\"RT\"] > lefthand_rt_90perc, \"accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f238b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot of RT vs accuracy for the right-handed subjects:\n",
    "righthanded_df = df[df[\"handedness\"] == \"right\"]\n",
    "righthanded_df.plot(kind=\"scatter\", x=\"RT\", y=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291a2f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the meteo dataset using the function below\n",
    "def get_meteo_dataset():\n",
    "    \"\"\"Get the meteo dataset from the open-meteo API.\n",
    "    Note how easy it is to get data from the web with pandas! As long as we give the URL of the csv data, pandas can read it.\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    URL = \"https://api.open-meteo.com/v1/forecast?latitude=52.52&longitude=13.41&hourly=temperature_2m,relativehumidity_2m,precipitation,windspeed_10m,winddirection_10m&start_date=2023-02-01&end_date=2023-05-28&format=csv\"\n",
    "    df = pd.read_csv(URL, skiprows=3)  # read the csv file, skipping the first 3 rows (a header)\n",
    "    df.columns = [col.split(\" \")[0] for col in df.columns]  # simplify column names\n",
    "    df[\"time\"] = pd.to_datetime(df[\"time\"])  # convert the time column to datetime\n",
    "    df[\"hour\"], df[\"dayofyear\"] = df[\"time\"].dt.hour, df[\"time\"].dt.dayofyear  # extract the hour and day of year\n",
    "    df[\"weekdays\"] = df[\"time\"].dt.day_name()  # extract the day of the week\n",
    "\n",
    "    # Here we artificially corrupt some of the data to make it more interesting\n",
    "    missing_idx = np.random.choice(df.index[:1000], 100)\n",
    "    df.loc[missing_idx, :] = np.nan\n",
    "    return df\n",
    "\n",
    "meteo_df = get_meteo_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b74c498",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c78a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the temperature and relative humidity for the first 1000 time points. \n",
    "# Find points where there's missing data (interrupted line).\n",
    "meteo_df.loc[:1000, \"temperature_2m\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599b76c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new interpolated temperature column by interpolating the temperature column of the dataframe:\n",
    "meteo_df[\"temperature_2m_interp\"] = meteo_df[\"temperature_2m\"].interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805126a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new plot with the interpolated temperature and the non-interpolated temperature \n",
    "# (plot the interpolated first!)\n",
    "meteo_df.loc[:1000, \"temperature_2m_interp\"].plot()\n",
    "meteo_df.loc[:1000, \"temperature_2m\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b1a71e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course-env",
   "language": "python",
   "name": "course-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
